{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Imputation for the three main predictors: credit score, delinquency rate, and income. We will merge these with the education data on FIPS code\n",
    "creditScore = pd.read_csv('Pre_cleaned_data/cty_cred_score_rP_gP_pall.csv')\n",
    "creditScore['FIPS'] = creditScore['cty'].str[3:]\n",
    "creditScore = creditScore.drop(columns=['cty']).rename(columns={'Average_credit_score_rP_gP_pall': 'avg_credit_score'})\n",
    "creditScore['avg_credit_score'] = creditScore['avg_credit_score'].fillna(creditScore['avg_credit_score'].mean())\n",
    "\n",
    "\n",
    "Delinq = pd.read_csv('Pre_cleaned_data/cty_deliq_rate_rP_gP_p25.csv')\n",
    "Delinq['FIPS'] = Delinq['cty'].str[3:]\n",
    "Delinq = Delinq.drop(columns=['cty','Name']).rename(columns={'Debt_Delinquency_rP_gP_p25': 'avg_delinquency_rate'})\n",
    "Delinq['avg_delinquency_rate'] = Delinq['avg_delinquency_rate'].fillna(Delinq['avg_delinquency_rate'].mean())\n",
    "\n",
    "Income = pd.read_csv('Pre_cleaned_data/cty_kir_staycz_rP_gP_p25.csv')\n",
    "Income['FIPS'] = Income['cty'].str[3:]\n",
    "Income = Income.drop(columns=['cty','Name']).rename(columns={'Individual_Income_Stayed_in_Commuting_Zone_rP_gP_p25': 'avg_income'})\n",
    "Income['avg_income'] = Income['avg_income'].fillna(Income['avg_income'].mean())\n",
    "\n",
    "Edu_Data = pd.read_csv('Pre_cleaned_data/EduFund_1996_2003c.csv')\n",
    "Edu_Data['FIPS'] = Edu_Data['FIPS'].astype(str).str.zfill(5)\n",
    "\n",
    "\n",
    "left_joined_data = pd.merge(creditScore, Delinq, on='FIPS', how='left')\n",
    "final_data = pd.merge(left_joined_data, Income, on='FIPS', how='left')\n",
    "final_data = pd.merge(final_data, Edu_Data, on='FIPS', how='left')\n",
    "\n",
    "final_data.dropna(inplace=True)\n",
    "final_data.drop(columns=['SchoolYear','Name','SupportServicesTotal_adj','LocalCharter_adj','StateTransport_adj'], inplace=True)\n",
    "\n",
    "cols_to_drop = [col for col in final_data.columns if 'PCT' in col]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "final_data.drop(columns=cols_to_drop, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "X = final_data.drop(columns=[\"avg_credit_score\",\"avg_delinquency_rate\"])\n",
    "y = final_data[\"avg_credit_score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "selected_columns = X.columns[X.columns.isin([\"FederalComp_adj\",\"FederalNutrition_adj\",\"FederalOther_adj\",\"StateFormula_adj\",\"StateOther_adj\",\"PupilSupport_adj\"])]\n",
    "X_train = X_train[selected_columns]\n",
    "X_test = X_test[selected_columns]\n",
    "X = X[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85778e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature        VIF\n",
      "0                 const  14.349025\n",
      "1       FederalComp_adj   1.376581\n",
      "2  FederalNutrition_adj   1.373790\n",
      "3      FederalOther_adj   1.121925\n",
      "4      StateFormula_adj   1.053638\n",
      "5        StateOther_adj   1.130257\n",
      "6      PupilSupport_adj   1.058981\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       avg_credit_score   R-squared:                       0.500\n",
      "Model:                            OLS   Adj. R-squared:                  0.499\n",
      "Method:                 Least Squares   F-statistic:                     449.7\n",
      "Date:                Sun, 22 Feb 2026   Prob (F-statistic):               0.00\n",
      "Time:                        01:05:39   Log-Likelihood:                -13880.\n",
      "No. Observations:                3113   AIC:                         2.777e+04\n",
      "Df Residuals:                    3106   BIC:                         2.782e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              715.8867      4.437    161.340      0.000     707.190     724.583\n",
      "FederalNutrition_adj    -0.2705      0.007    -36.553      0.000      -0.285      -0.256\n",
      "FederalComp_adj          0.0131      0.005      2.778      0.005       0.004       0.022\n",
      "FederalOther_adj         0.0001      0.001      0.084      0.933      -0.003       0.003\n",
      "StateFormula_adj         0.0014      0.000      3.211      0.001       0.001       0.002\n",
      "StateOther_adj          -0.0027      0.001     -2.950      0.003      -0.004      -0.001\n",
      "PupilSupport_adj        -0.0081      0.013     -0.636      0.525      -0.033       0.017\n",
      "==============================================================================\n",
      "Omnibus:                      360.678   Durbin-Watson:                   0.834\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              668.590\n",
      "Skew:                           0.757   Prob(JB):                    6.57e-146\n",
      "Kurtosis:                       4.692   Cond. No.                     1.29e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large, 1.29e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Breusch-Pagan test statistic: 109.72522390077263\n",
      "Breusch-Pagan test p-value: 2.327137229167536e-21\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# check for multicollinearity using VIF\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"feature\"] = X.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(vif_df)\n",
    "\n",
    "# fit the OLS model with robust standard errors\n",
    "ols_model = smf.ols(formula=\"avg_credit_score ~ FederalNutrition_adj + FederalComp_adj + FederalOther_adj + StateFormula_adj + StateOther_adj + PupilSupport_adj\", data=final_data).fit(cov_type='HC3')\n",
    "print(ols_model.summary())\n",
    "bp_test = het_breuschpagan(ols_model.resid, ols_model.model.exog)\n",
    "\n",
    "# check for heteroscedasticity using the Breusch-Pagan test\n",
    "print(\"Breusch-Pagan test statistic:\", bp_test[0])\n",
    "print(\"Breusch-Pagan test p-value:\", bp_test[1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counties: 3113\n",
      "Long rows (should be approx unique_counties * 6 if 1 row/county): 18678\n",
      "county_long shape: (18678, 11)\n",
      "Rows per county (should be 6 if 1 row/county):\n",
      "6    3113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "OUTCOME_COL = \"avg_credit_score\"\n",
    "ID_COL = \"FIPS\"\n",
    "\n",
    "PREDICTOR_COLS = [\n",
    "    \"FederalComp_adj\",\n",
    "    \"FederalNutrition_adj\",\n",
    "    \"FederalOther_adj\",\n",
    "    \"StateFormula_adj\",\n",
    "    \"StateOther_adj\",\n",
    "    \"PupilSupport_adj\"\n",
    "]\n",
    "\n",
    "ROBUST_SE_TYPE = \"HC3\"\n",
    "\n",
    "\n",
    "missing = [c for c in [ID_COL, OUTCOME_COL] + PREDICTOR_COLS if c not in final_data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
    "\n",
    "\n",
    "n_counties = final_data[ID_COL].nunique()\n",
    "print(\"Unique counties:\", n_counties)\n",
    "\n",
    "\n",
    "#  Build LONG table \n",
    "\n",
    "base = final_data[[ID_COL, OUTCOME_COL] + PREDICTOR_COLS].copy()\n",
    "\n",
    "county_long = base.melt(\n",
    "    id_vars=[ID_COL, OUTCOME_COL],\n",
    "    value_vars=PREDICTOR_COLS,\n",
    "    var_name=\"predictor\",\n",
    "    value_name=\"spend_dollars\"\n",
    ")\n",
    "\n",
    "# per-$1,000 units (for ROI interpretation)\n",
    "county_long[\"spend_k\"] = county_long[\"spend_dollars\"].astype(float) / 1000.0\n",
    "\n",
    "print(\"Long rows (should be approx unique_counties * 6 if 1 row/county):\", county_long.shape[0])\n",
    "\n",
    "\n",
    "# Fit the multivariate OLS on COMPLETE CASES (unique partial effects)\n",
    "\n",
    "df_model = base.dropna(subset=[OUTCOME_COL] + PREDICTOR_COLS).copy()\n",
    "\n",
    "# build X in $1,000 units\n",
    "X = df_model[PREDICTOR_COLS].astype(float) / 1000.0\n",
    "X = sm.add_constant(X)\n",
    "y = df_model[OUTCOME_COL].astype(float)\n",
    "\n",
    "ols = sm.OLS(y, X).fit()\n",
    "ols_r = ols.get_robustcov_results(cov_type=ROBUST_SE_TYPE)\n",
    "\n",
    "betas = pd.Series(ols_r.params, index=ols_r.model.exog_names)\n",
    "\n",
    "# ROI mapping: predictor -> points per $1,000\n",
    "roi_map = {p: float(betas.get(p, np.nan)) for p in PREDICTOR_COLS}\n",
    "county_long[\"roi_points_per_1000\"] = county_long[\"predictor\"].map(roi_map)\n",
    "\n",
    "\n",
    "# Contributions vs \"average county\" baseline (continuous)\n",
    "# Contribution = beta * (x_i - mean(x)) in $1,000 units\n",
    "\n",
    "means_k = (df_model[PREDICTOR_COLS].astype(float) / 1000.0).mean()  # mean spend_k in the model sample\n",
    "county_long[\"mean_spend_k_model\"] = county_long[\"predictor\"].map(means_k.to_dict())\n",
    "\n",
    "county_long[\"contribution_points_vs_baseline\"] = (\n",
    "    county_long[\"roi_points_per_1000\"] * (county_long[\"spend_k\"] - county_long[\"mean_spend_k_model\"])\n",
    ")\n",
    "\n",
    "# Baseline predicted credit for \"average county\" \n",
    "baseline = float(betas.get(\"const\", 0.0) + (betas[PREDICTOR_COLS] * means_k[PREDICTOR_COLS]).sum())\n",
    "county_long[\"baseline_pred_credit\"] = baseline\n",
    "\n",
    "def dollars_for_100(b):\n",
    "    return (1000.0 * (100.0 / b)) if (np.isfinite(b) and b > 0) else np.nan\n",
    "\n",
    "d100_map = {p: dollars_for_100(roi_map[p]) for p in PREDICTOR_COLS}\n",
    "county_long[\"dollars_for_100_credit_points\"] = county_long[\"predictor\"].map(d100_map)\n",
    "\n",
    "# Add model-predicted credit at the county row level \n",
    "\n",
    "df_model[\"_pred_credit\"] = ols.predict(X)\n",
    "county_long = county_long.merge(\n",
    "    df_model[[ID_COL, \"_pred_credit\"]],\n",
    "    on=ID_COL,\n",
    "    how=\"left\"\n",
    ").rename(columns={\"_pred_credit\": \"pred_credit\"})\n",
    "\n",
    "\n",
    "# Final checks\n",
    "print(\"county_long shape:\", county_long.shape)\n",
    "print(\"Rows per county (should be 6 if 1 row/county):\")\n",
    "print(county_long.groupby(ID_COL).size().value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f27daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_sklearn2 import AutoSklearnRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# AutoML with AutoSklearnRegressor\n",
    "automl = AutoSklearnRegressor(time_limit=100, random_state=42)\n",
    "\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc768135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.41908770281376884\n",
      "RMSE: 2867.6061224539485\n",
      "MAE: 2060.3134728604273\n",
      "\n",
      "Best model: {'preprocessor': 'minmax_scaler', 'regressor': 'extra_trees'}\n",
      "standard_scaler_random_forest: 0.4080\n",
      "standard_scaler_gradient_boosting: 0.3545\n",
      "standard_scaler_linear_regression: 0.1970\n",
      "standard_scaler_ridge: 0.1970\n",
      "standard_scaler_lasso: 0.1971\n",
      "standard_scaler_elastic_net: 0.1576\n",
      "standard_scaler_svr: -0.0140\n",
      "standard_scaler_knn: 0.3751\n",
      "standard_scaler_mlp: -24.8130\n",
      "standard_scaler_decision_tree: -0.2378\n",
      "standard_scaler_ada_boost: 0.1629\n",
      "standard_scaler_extra_trees: 0.4120\n",
      "standard_scaler_bagging: 0.3494\n",
      "standard_scaler_sgd: 0.1902\n",
      "standard_scaler_huber: 0.1905\n",
      "standard_scaler_poisson: 0.1828\n",
      "standard_scaler_gamma: 0.1196\n",
      "standard_scaler_tweedie: 0.1204\n",
      "standard_scaler_ransac: -0.3923\n",
      "standard_scaler_linear_svr: -26.9500\n",
      "standard_scaler_kernel_ridge: -32.4218\n",
      "standard_scaler_pls: 0.1880\n",
      "minmax_scaler_random_forest: 0.4080\n",
      "minmax_scaler_gradient_boosting: 0.3550\n",
      "minmax_scaler_linear_regression: 0.1970\n",
      "minmax_scaler_ridge: 0.1929\n",
      "minmax_scaler_lasso: 0.1977\n",
      "minmax_scaler_elastic_net: 0.0030\n",
      "minmax_scaler_svr: -0.0157\n",
      "minmax_scaler_knn: 0.3479\n",
      "minmax_scaler_mlp: -26.1425\n",
      "minmax_scaler_decision_tree: -0.2378\n",
      "minmax_scaler_ada_boost: 0.1629\n",
      "minmax_scaler_extra_trees: 0.4127\n",
      "minmax_scaler_bagging: 0.3491\n",
      "minmax_scaler_sgd: 0.1844\n",
      "minmax_scaler_huber: 0.1941\n",
      "minmax_scaler_poisson: 0.1835\n",
      "minmax_scaler_gamma: 0.0015\n",
      "minmax_scaler_tweedie: 0.0015\n",
      "minmax_scaler_ransac: -0.3923\n",
      "minmax_scaler_linear_svr: -25.5311\n",
      "minmax_scaler_kernel_ridge: -1.3371\n",
      "minmax_scaler_pls: 0.1880\n",
      "robust_scaler_random_forest: 0.4080\n",
      "robust_scaler_gradient_boosting: 0.3545\n",
      "robust_scaler_linear_regression: 0.1970\n",
      "robust_scaler_ridge: 0.1970\n",
      "robust_scaler_lasso: 0.1971\n",
      "robust_scaler_elastic_net: 0.1657\n",
      "robust_scaler_svr: -0.0129\n",
      "robust_scaler_knn: 0.3582\n",
      "robust_scaler_mlp: -24.3377\n",
      "robust_scaler_decision_tree: -0.2378\n",
      "robust_scaler_ada_boost: 0.1629\n",
      "robust_scaler_extra_trees: 0.4120\n",
      "robust_scaler_bagging: 0.3494\n",
      "robust_scaler_sgd: 0.1617\n",
      "robust_scaler_huber: 0.1904\n",
      "robust_scaler_poisson: 0.1828\n",
      "robust_scaler_gamma: 0.1334\n",
      "robust_scaler_tweedie: 0.1334\n",
      "robust_scaler_ransac: -0.3923\n",
      "robust_scaler_linear_svr: -25.2459\n",
      "robust_scaler_kernel_ridge: -28.9933\n",
      "robust_scaler_pls: 0.1880\n",
      "Pipeline(steps=[('preprocessor', MinMaxScaler()),\n",
      "                ('regressor', ExtraTreesRegressor(n_jobs=-1, random_state=42))])\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesRegressor'>\n",
      "Percentage RMSE: 13.087178668223027\n",
      "Standard Deviation of y_train: 3841.876338760012\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"\\nBest model: {automl.best_params}\")\n",
    "for model_name, score in automl.get_models_performance().items():\n",
    "    print(f\"{model_name}: {score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the best model and its weight\n",
    "best_model = automl.best_model\n",
    "print(best_model)\n",
    "\n",
    "final_estimator = best_model.steps[-1][1]\n",
    "print(type(final_estimator))\n",
    "\n",
    "importances = final_estimator.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "print(f\"Percentage RMSE: {(rmse / y_train.mean()) * 100}\")\n",
    "print(f\"Standard Deviation of y_train: {y_train.std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
