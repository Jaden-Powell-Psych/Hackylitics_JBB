{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e9da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7aa2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Imputation for the three main predictors: credit score, delinquency rate, and income. We will merge these with the education data on FIPS code\n",
    "creditScore = pd.read_csv('Pre_cleaned_data/cty_cred_score_rP_gP_pall.csv')\n",
    "creditScore['FIPS'] = creditScore['cty'].str[3:]\n",
    "creditScore = creditScore.drop(columns=['cty']).rename(columns={'Average_credit_score_rP_gP_pall': 'avg_credit_score'})\n",
    "creditScore['avg_credit_score'] = creditScore['avg_credit_score'].fillna(creditScore['avg_credit_score'].mean())\n",
    "\n",
    "\n",
    "Delinq = pd.read_csv('Pre_cleaned_data/cty_deliq_rate_rP_gP_p25.csv')\n",
    "Delinq['FIPS'] = Delinq['cty'].str[3:]\n",
    "Delinq = Delinq.drop(columns=['cty','Name']).rename(columns={'Debt_Delinquency_rP_gP_p25': 'avg_delinquency_rate'})\n",
    "Delinq['avg_delinquency_rate'] = Delinq['avg_delinquency_rate'].fillna(Delinq['avg_delinquency_rate'].mean())\n",
    "\n",
    "Income = pd.read_csv('Pre_cleaned_data/cty_kir_staycz_rP_gP_p25.csv')\n",
    "Income['FIPS'] = Income['cty'].str[3:]\n",
    "Income = Income.drop(columns=['cty','Name']).rename(columns={'Individual_Income_Stayed_in_Commuting_Zone_rP_gP_p25': 'avg_income'})\n",
    "Income['avg_income'] = Income['avg_income'].fillna(Income['avg_income'].mean())\n",
    "\n",
    "Edu_Data = pd.read_csv('Pre_cleaned_data/EduFund_1996_2003c.csv')\n",
    "Edu_Data['FIPS'] = Edu_Data['FIPS'].astype(str).str.zfill(5)\n",
    "\n",
    "\n",
    "left_joined_data = pd.merge(creditScore, Delinq, on='FIPS', how='left')\n",
    "final_data = pd.merge(left_joined_data, Income, on='FIPS', how='left')\n",
    "final_data = pd.merge(final_data, Edu_Data, on='FIPS', how='left')\n",
    "\n",
    "final_data.dropna(inplace=True)\n",
    "final_data.drop(columns=['SchoolYear','SupportServicesTotal_adj','LocalCharter_adj','StateTransport_adj'], inplace=True)\n",
    "\n",
    "\n",
    "crosswalk = final_data[['Name','FIPS']]\n",
    "crosswalk['FIPS_STATE'] = crosswalk['FIPS'].str[:2]\n",
    "crosswalk['FIPS_COUNTY'] = crosswalk['FIPS'].str[2:]\n",
    "crosswalk['COUNTY_NAME'] = crosswalk['Name'].str.split(',').str[0]\n",
    "crosswalk['STATE_NAME'] = crosswalk['Name'].str.split(',').str[1].str.strip()\n",
    "crosswalk.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "\n",
    "cols_to_drop = [col for col in final_data.columns if 'PCT' in col]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "final_data.drop(columns=cols_to_drop, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "X = final_data.drop(columns=[\"avg_credit_score\",\"avg_delinquency_rate\"])\n",
    "y = final_data[\"avg_delinquency_rate\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "selected_columns = [\"avg_delinquency_rate\", \"FederalNutrition_adj\", \"FederalComp_adj\", \"FederalOther_adj\", \"StateFormula_adj\", \"StateOther_adj\", \"PupilSupport_adj\", \"FIPS\"]\n",
    "data = final_data[selected_columns].copy()\n",
    "data = data.merge(crosswalk, on=\"FIPS\", how=\"left\", suffixes=(\"\", \"_crosswalk\"))\n",
    "\n",
    "\n",
    "#X = X[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85778e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature        VIF\n",
      "0                 const  14.349025\n",
      "1       FederalComp_adj   1.376581\n",
      "2  FederalNutrition_adj   1.373790\n",
      "3      FederalOther_adj   1.121925\n",
      "4      StateFormula_adj   1.053638\n",
      "5        StateOther_adj   1.130257\n",
      "6      PupilSupport_adj   1.058981\n",
      "                             OLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     avg_delinquency_rate   R-squared:                       0.332\n",
      "Model:                              OLS   Adj. R-squared:                  0.331\n",
      "Method:                   Least Squares   F-statistic:                     250.5\n",
      "Date:                  Sun, 22 Feb 2026   Prob (F-statistic):          9.03e-262\n",
      "Time:                          04:00:50   Log-Likelihood:                 2703.3\n",
      "No. Observations:                  3113   AIC:                            -5393.\n",
      "Df Residuals:                      3106   BIC:                            -5350.\n",
      "Df Model:                             6                                         \n",
      "Covariance Type:                    HC3                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.4234      0.023     18.689      0.000       0.379       0.468\n",
      "FederalNutrition_adj     0.0009   3.34e-05     28.158      0.000       0.001       0.001\n",
      "FederalComp_adj         -0.0001   2.12e-05     -5.100      0.000      -0.000   -6.66e-05\n",
      "FederalOther_adj     -2.259e-05   6.31e-06     -3.578      0.000    -3.5e-05   -1.02e-05\n",
      "StateFormula_adj     -9.988e-06   2.09e-06     -4.785      0.000   -1.41e-05    -5.9e-06\n",
      "StateOther_adj        1.064e-05   4.14e-06      2.571      0.010    2.53e-06    1.88e-05\n",
      "PupilSupport_adj      9.885e-05    6.5e-05      1.521      0.128   -2.85e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      399.002   Durbin-Watson:                   0.903\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              750.095\n",
      "Skew:                          -0.819   Prob(JB):                    1.31e-163\n",
      "Kurtosis:                       4.761   Cond. No.                     1.29e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large, 1.29e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Breusch-Pagan test statistic: 138.92849011653223\n",
      "Breusch-Pagan test p-value: 1.6867734296504206e-27\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       avg_credit_score   R-squared:                       0.638\n",
      "Model:                            OLS   Adj. R-squared:                  0.638\n",
      "Method:                 Least Squares   F-statistic:                     681.7\n",
      "Date:                Sun, 22 Feb 2026   Prob (F-statistic):               0.00\n",
      "Time:                        04:00:50   Log-Likelihood:                -13377.\n",
      "No. Observations:                3113   AIC:                         2.677e+04\n",
      "Df Residuals:                    3105   BIC:                         2.682e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                         623.0395      9.317     66.873      0.000     604.779     641.300\n",
      "FederalComp_adj                    -0.0088      0.027     -0.330      0.741      -0.061       0.044\n",
      "avg_income                          0.0035      0.000      8.397      0.000       0.003       0.004\n",
      "FederalComp_adj:avg_income        6.17e-07   1.37e-06      0.449      0.654   -2.08e-06    3.31e-06\n",
      "FederalNutrition_adj               -0.0890      0.055     -1.623      0.105      -0.196       0.018\n",
      "FederalNutrition_adj:avg_income -5.739e-06   2.79e-06     -2.054      0.040   -1.12e-05   -2.62e-07\n",
      "StateFormula_adj                 3.789e-05      0.003      0.013      0.989      -0.006       0.006\n",
      "StateFormula_adj:avg_income      1.122e-07   1.32e-07      0.851      0.395   -1.46e-07    3.71e-07\n",
      "==============================================================================\n",
      "Omnibus:                      184.868   Durbin-Watson:                   1.218\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              351.979\n",
      "Skew:                           0.428   Prob(JB):                     3.71e-77\n",
      "Kurtosis:                       4.408   Cond. No.                     1.29e+09\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large, 1.29e+09. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# check for multicollinearity using VIF\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"feature\"] = X.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(vif_df)\n",
    "\n",
    "# fit the OLS model with robust standard errors\n",
    "ols_model = smf.ols(formula=\"avg_delinquency_rate ~ FederalNutrition_adj + FederalComp_adj + FederalOther_adj + StateFormula_adj + StateOther_adj + PupilSupport_adj\", data=final_data).fit(cov_type='HC3')\n",
    "print(ols_model.summary())\n",
    "bp_test = het_breuschpagan(ols_model.resid, ols_model.model.exog)\n",
    "\n",
    "# check for heteroscedasticity using the Breusch-Pagan test\n",
    "print(\"Breusch-Pagan test statistic:\", bp_test[0])\n",
    "print(\"Breusch-Pagan test p-value:\", bp_test[1])\n",
    "\n",
    "formula = \"avg_credit_score ~ FederalComp_adj * avg_income + FederalNutrition_adj * avg_income + StateFormula_adj * avg_income\"\n",
    "\n",
    "model_interact = smf.ols(formula=formula, data=final_data).fit(cov_type='HC3')\n",
    "print(model_interact.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce2bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counties: 3113\n",
      "Long rows (should be approx unique_counties * 6 if 1 row/county): 18678\n",
      "county_long shape: (18678, 13)\n",
      "Rows per county (should be 6 if 1 row/county):\n",
      "6    3113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "OUTCOME_COL = \"avg_delinquency_rate\"\n",
    "ID_COL = \"FIPS\"\n",
    "\n",
    "PREDICTOR_COLS = [\n",
    "    \"FederalComp_adj\",\n",
    "    \"FederalNutrition_adj\",\n",
    "    \"FederalOther_adj\",\n",
    "    \"StateFormula_adj\",\n",
    "    \"StateOther_adj\",\n",
    "    \"PupilSupport_adj\"\n",
    "]\n",
    "MODERATOR = \"avg_income\"\n",
    "\n",
    "ROBUST_SE_TYPE = \"HC3\"\n",
    "\n",
    "\n",
    "missing = [c for c in [ID_COL, OUTCOME_COL] + PREDICTOR_COLS if c not in final_data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
    "\n",
    "\n",
    "n_counties = final_data[ID_COL].nunique()\n",
    "print(\"Unique counties:\", n_counties)\n",
    "\n",
    "\n",
    "#  Build LONG table \n",
    "\n",
    "base = final_data[[ID_COL, OUTCOME_COL, MODERATOR] + PREDICTOR_COLS].copy()\n",
    "\n",
    "county_long = base.melt(\n",
    "    id_vars=[ID_COL, OUTCOME_COL, MODERATOR],\n",
    "    value_vars=PREDICTOR_COLS,\n",
    "    var_name=\"predictor\",\n",
    "    value_name=\"spend_dollars\"\n",
    ")\n",
    "\n",
    "# per-$1,000 units (for ROI interpretation)\n",
    "county_long[\"spend_k\"] = county_long[\"spend_dollars\"].astype(float) / 1000.0\n",
    "\n",
    "print(\"Long rows (should be approx unique_counties * 6 if 1 row/county):\", county_long.shape[0])\n",
    "\n",
    "\n",
    "# Fit the multivariate OLS on COMPLETE CASES (unique partial effects)\n",
    "\n",
    "df_model = base.dropna(subset=[OUTCOME_COL] + PREDICTOR_COLS).copy()\n",
    "\n",
    "# build X in $1,000 units\n",
    "X = df_model[PREDICTOR_COLS].astype(float) / 1000.0\n",
    "X_mod = df_model[MODERATOR] / 1000.0 \n",
    "\n",
    "# Add the 'moderator' (income) to X for the interaction\n",
    "# Ensure it is also scaled if necessary (e.g., in $1,000s)\n",
    "X['avg_income_k'] = df_model['avg_income'] / 1000.0\n",
    "\n",
    "# Create manual interaction terms\n",
    "# Example: FederalComp ROI now depends on Income\n",
    "for col in PREDICTOR_COLS:\n",
    "    X[f'{col}_x_income'] = X[col] * X_mod\n",
    "\n",
    "y = df_model[OUTCOME_COL].astype(float)\n",
    "X = sm.add_constant(X)\n",
    "ols = sm.OLS(df_model[OUTCOME_COL], X).fit()\n",
    "ols_r = ols.get_robustcov_results(cov_type=ROBUST_SE_TYPE)\n",
    "betas = ols_r.params\n",
    "betas = pd.Series(ols_r.params, index=ols_r.model.exog_names)\n",
    "\n",
    "# ROI mapping: predictor -> points per $1,000\n",
    "income_map = base.set_index(ID_COL)['avg_income'].to_dict()\n",
    "county_long['avg_income_k'] = county_long[ID_COL].map(income_map) / 1000.0\n",
    "\n",
    "X_mean = X.mean().to_frame().T \n",
    "baseline = float(ols_r.predict(X_mean)[0])\n",
    "county_long[\"baseline_pred_credit\"] = baseline\n",
    "\n",
    "def get_dynamic_roi(row):\n",
    "    p = row['predictor']\n",
    "    inc_k = row[MODERATOR] / 1000.0\n",
    "    # ROI = Base Beta + (Interaction Beta * County Income)\n",
    "    return betas.get(p, 0) + (betas.get(f\"{p}_x_income\", 0) * inc_k)\n",
    "\n",
    "# Apply to every row - roi_points_per_1000 will now fluctuate!\n",
    "county_long[\"roi_points_per_1000\"] = county_long.apply(get_dynamic_roi, axis=1)\n",
    "\n",
    "\n",
    "# Instead of mapping a dictionary, calculate directly on the Series.\n",
    "# This ensures it's dynamic to the data in each specific row.\n",
    "county_long[\"dollars_for_1_pt_reduction\"] = (\n",
    "    1000.0 * (1.0 / county_long[\"roi_points_per_1000\"].abs())\n",
    ").where((county_long[\"roi_points_per_1000\"] < 0) & np.isfinite(county_long[\"roi_points_per_1000\"]))\n",
    "\n",
    "# Contributions vs \"average county\" baseline (continuous)\n",
    "# Contribution = beta * (x_i - mean(x)) in $1,000 units\n",
    "\n",
    "means_k = (df_model[PREDICTOR_COLS].astype(float) / 1000.0).mean().to_dict()\n",
    "county_long[\"mean_spend_k_model\"] = county_long[\"predictor\"].map(means_k)\n",
    "\n",
    "county_long[\"contribution_points_vs_baseline\"] = (\n",
    "    county_long[\"roi_points_per_1000\"] * (county_long[\"spend_k\"] - county_long[\"mean_spend_k_model\"])\n",
    ")\n",
    "\n",
    "# Baseline predicted credit for \"average county\" \n",
    "means_k = (df_model[PREDICTOR_COLS].astype(float) / 1000.0).mean() \n",
    "baseline = float(\n",
    "    betas.get(\"const\", 0.0) + \n",
    "    (betas.loc[PREDICTOR_COLS] * means_k.loc[PREDICTOR_COLS]).sum()\n",
    ")\n",
    "county_long[\"baseline_pred_credit\"] = baseline\n",
    "\n",
    "\n",
    "def calculate_dollars_dynamic(roi_series):\n",
    "    # Vectorized check: if ROI is finite and > 0, calculate. Otherwise, NaN.\n",
    "    return 1000.0 * (100.0 / roi_series).where((roi_series > 0) & np.isfinite(roi_series))\n",
    "\n",
    "# Assign directly to the dataframe\n",
    "\n",
    "# Add model-predicted credit at the county row level \n",
    "\n",
    "df_model[\"_pred_credit\"] = ols.predict(X)\n",
    "county_long = county_long.merge(\n",
    "    df_model[[ID_COL, \"_pred_credit\"]],\n",
    "    on=ID_COL,\n",
    "    how=\"left\"\n",
    ").rename(columns={\"_pred_credit\": \"pred_credit\"})\n",
    "\n",
    "\n",
    "# Final checks\n",
    "print(\"county_long shape:\", county_long.shape)\n",
    "print(\"Rows per county (should be 6 if 1 row/county):\")\n",
    "print(county_long.groupby(ID_COL).size().value_counts().head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f27daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_sklearn2 import AutoSklearnRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# AutoML with AutoSklearnRegressor\n",
    "automl = AutoSklearnRegressor(time_limit=100, random_state=42)\n",
    "\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc768135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"\\nBest model: {automl.best_params}\")\n",
    "for model_name, score in automl.get_models_performance().items():\n",
    "    print(f\"{model_name}: {score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the best model and its weight\n",
    "best_model = automl.best_model\n",
    "print(best_model)\n",
    "\n",
    "final_estimator = best_model.steps[-1][1]\n",
    "print(type(final_estimator))\n",
    "\n",
    "importances = final_estimator.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "print(f\"Percentage RMSE: {(rmse / y_train.mean()) * 100}\")\n",
    "print(f\"Standard Deviation of y_train: {y_train.std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
